% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{book}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
\fi
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\usepackage{booktabs}

\usepackage{color}
\usepackage{framed}
\setlength{\fboxsep}{.8em}

% These colours were manually entered, they shouldn't matter unless you want pdf output

\newenvironment{redbox}{
  \definecolor{shadecolor}{RGB}{243, 154, 157}
  \color{white}
  \begin{shaded}}
 {\end{shaded}}

\newenvironment{bluebox}{
  \definecolor{shadecolor}{RGB}{172, 210, 237}
  \color{white}
  \begin{shaded}}
 {\end{shaded}}

\newenvironment{greenbox}{
  \definecolor{shadecolor}{RGB}{141, 181, 128}
  \color{white}
  \begin{shaded}}
 {\end{shaded}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Pathogen Genomic Epidemiology 2025},
  pdfauthor={Faculty: Angela McLaughlin, Emma Griffiths, Finlay Maguire, Gary Van Domselaar, Idowu Olawoye, Jennifer Guthrie, Charlie Barclay,},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Pathogen Genomic Epidemiology 2025}
\author{Faculty: Angela McLaughlin, Emma Griffiths, Finlay Maguire, Gary Van Domselaar, Idowu Olawoye, Jennifer Guthrie, Charlie Barclay,}
\date{November 24-26, 2025}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\part{Introduction}\label{part-introduction}

\chapter{Workshop Info}\label{workshop-info}

Welcome to the 2025 Pathogen Genomic Epidemiology Canadian Bioinformatics Workshop webpage!

\section{Pre-work}\label{pre-work}

\section{Class Photo}\label{class-photo}

Coming soon!

\section{Schedule}\label{schedule}

\chapter{Meet Your Faculty}\label{meet-your-faculty}

\subsubsection{Angela McLaughlin}\label{angela-mclaughlin}

\begin{quote}
Postdoctoral Fellow
Dalhousie University and University of Guelph
Burnaby, BC, Canada

--- \href{mailto:ez928230@dal.ca}{\nolinkurl{ez928230@dal.ca}}
\end{quote}

Angela McLaughlin is a postdoctoral fellow in Dr.~Finlay Maguire's lab at Dalhousie University, in collaboration with Dr.~Zvonimir Poljak at University of Guelph. Her research interests span viral phylogenetics (HIV-1, SARS-CoV-2, and influenza virus), genomic epidemiology, bioinformatics, public health, wildlife surveillance, and statistical/machine learning/mathematical models of pathogen transmission. Her current project aims to predict host specificity of avian influenza virus H5Nx using machine learning models of viral genomic features with phylogenetics-informed cross-validation and hierarchical segment to whole genome ensemble models.

\subsubsection{Emma Griffiths}\label{emma-griffiths}

\begin{quote}
Research Associate, Faculty of Health Sciences
Simon Fraser University
Vancouver, BC, Canada

--- \href{mailto:emma_griffiths@sfu.ca}{\nolinkurl{emma\_griffiths@sfu.ca}}
\end{quote}

Emma Griffiths is a research associate at the Centre for Infectious Disease Genomics and One Health (CIDGOH) in the Faculty of Health Sciences at Simon Fraser University in Vancouver, Canada. Her work focuses on developing and implementing ontologies and data standards for public health and food safety genomics to help improve data harmonization and integration. She is a member of the Standards Council of Canada and leads the Public Health Alliance for Genomic Epidemiology (PHA4GE) Data Structures Working Group.

\subsubsection{Finlay Maguire}\label{finlay-maguire}

\begin{quote}
Assistant Professor, Faculty of Computer Science and Department of Community Health \& Epidemiology,
Dalhousie University
Halifax, MS, Canada

--- \href{mailto:finlay.maguire@dal.ca}{\nolinkurl{finlay.maguire@dal.ca}}, finlaymagui.re
\end{quote}

Finlay Maguire is a genomic epidemiologist whose work centers on leveraging data in innovative ways to answer questions related to applied health and social issues. This includes developing bioinformatics methods to more effectively use genomic data to mitigate infectious diseases and broad interdisciplinary collaborations in areas such as refugee healthcare provision and online radicalisation. They are an active contributor to the national and international public health responses to emerging viral zoonoses and antimicrobial resistance, co-chair of the PHA4GE data structures working group, and act as a Pathogenomics Bioinformatics Lead for Sunnybrook's Shared Hospital Laboratory.

\subsubsection{Gary Van Domselaar}\label{gary-van-domselaar}

\begin{quote}
Chief, Bioinformatics, National Microbiology Laboratory
Public Health Agency of Canada
Winnipeg, MB, Canada

--- \href{mailto:gary.vandomselaar@phac-aspc.gc.ca}{\nolinkurl{gary.vandomselaar@phac-aspc.gc.ca}}
\end{quote}

Dr.~Gary Van Domselaar, PhD (University of Alberta, 2003) is the Chief of the Bioinformatics Section at the National Microbiology Laboratory in Winnipeg Canada and Associate Professor in the Department of Medical Microbiology and Infectious Diseases at the University of Manitoba. Dr.~Van Domselaar's lab develops bioinformatics methods and pipelines to understand, track, and control circulating infectious diseases in Canada and globally. His research and development activities span metagenomics, infectious disease genomic epidemiology, genome annotation, population structure analysis, and microbial genome wide association studies.

\subsubsection{Idowu Olawoye}\label{idowu-olawoye}

\begin{quote}
Postdoctoral Associate
University of Western Ontario
London, ON, Canada

--- \href{mailto:iolawoye@uwo.ca}{\nolinkurl{iolawoye@uwo.ca}}
\end{quote}

Idowu is a postdoctoral associate in the Guthrie Lab at the University of Western Ontario. His research focuses on utilizing computational biology to understand transmission patterns, genomic evolution, and antimicrobial resistance of bacterial pathogens. He has been involved in numerous bioinformatics workshops and trainings across Africa and most recently in Canada.

\subsubsection{Jennifer Guthrie}\label{jennifer-guthrie}

\begin{quote}
Assistant Professor
University of Western Ontario
London, ON, Canada

--- \href{mailto:jennifer.guthrie@uwo.ca}{\nolinkurl{jennifer.guthrie@uwo.ca}}
\end{quote}

Dr.~Jennifer Guthrie is a Canada Research Chair in Pathogen Genomics and Bioinformatics and Assistant Professor in the Departments of Microbiology \& Immunology and Epidemiology \& Biostatistics at Western University; she also serves as an Adjunct Scientist at Public Health Ontario. A genomic epidemiologist by training, in her research Dr.~Guthrie uses interdisciplinary approaches combining principles from data science and bioinformatics, and more traditional epidemiology and microbiology methods to further our understanding of disease transmission dynamics, antimicrobial resistance, and epidemiological characteristics of pathogens. Her research involves pathogens of public health importance such as SARS-CoV-2, influenza, Mycobacterium tuberculosis, and methicillin resistant Staphylococcus aureus.

\subsubsection{Zhibin Lu}\label{zhibin-lu}

\begin{quote}
Senior Manager, Digital Research University Health Network
Toronto, ON, Canada ---
\href{mailto:zhibin@gmail.com}{\nolinkurl{zhibin@gmail.com}}
\end{quote}

Zhibin Lu is a senior manager at University Health Network Digital. He is responsible for UHN HPC operations and scientific software. He manages two HPC clusters at UHN, including system administration, user management, and maintenance of bioinformatics tools for HPC4health. He is also skilled in Next-Gen sequence data analysis and has developed and maintained bioinformatics pipelines at the Bioinformatics and HPC Core. He is a member of the Digital Research Alliance of Canada Bioinformatics National Team and Scheduling National Team.

\subsubsection{Charlie Barclay}\label{charlie-barclay}

\begin{quote}
MSc Graduate Student Researcher
University of British Columbia
Vancouver, BC, Canada

--- \href{mailto:cbarcl01@mail.ubc.ca}{\nolinkurl{cbarcl01@mail.ubc.ca}}
\end{quote}

Charlie is an ontology curator at the Centre for Infectious Disease Genomics and One Health (CIDGOH), focusing on data standards for contextual data of genomic epidemiology, including wastewater surveillance. With five years of experience in data management, specializing in biodiversity and genomics data, she also actively contributes to the Public Health Alliance for Genomic Epidemiology (PHA4GE) and the Global Alliance for Genomics and Health (GA4GH).

\chapter{Data and Compute Setup}\label{data-and-compute-setup}

\subsubsection{Course data downloads}\label{course-data-downloads}

Coming soon!

\subsubsection{Compute setup}\label{compute-setup}

Coming soon!

\chapter{Module 1 Data Curation and Data Sharing}\label{module-1-data-curation-and-data-sharing}

\section{Lecture}\label{lecture}

\section{Lab}\label{lab}

\chapter{Module 2 Emerging Pathogen Detection and Identification}\label{module-2-emerging-pathogen-detection-and-identification}

\section{Lecture}\label{lecture-1}

\section{Lab}\label{lab-1}

\chapter{Module 3 Pathogen Typing}\label{module-3-pathogen-typing}

\section{Lecture}\label{lecture-2}

\section{Lab}\label{lab-2}

\subsection{Introduction}\label{introduction}

The scope of this practical session is to perform a core-genome multi-locus sequence typing (cgMLST) analysis, a genome-based molecular typing method widely adopted for genomic surveillance of bacterial species.

Due to the widespread adoption of high-throughput whole-genome sequencing (WGS) and the advancement of this technology, it has been incorporated in many surveillance programs such as \href{https://www.canada.ca/en/public-health/programs/pulsenet-canada.html}{PulseNet Canada to monitor foodborne outbreaks}.

This practical is split into two sessions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  cgMLST allele schema creation all through to allele calling, which will be conducted on your terminal to generate necessary input files for the next session
\item
  Clustering of cgMLST data from chewBBACA and visualization in RStudio
\end{enumerate}

In this exercise, you will begin by generating cgMLST allele calls for a collection of 200 \emph{Staphylococcus aureus} genomes (50 complete and 150 draft genomes) from NCBI RefSeq and BVBRC.

\subsection{PART ONE: chewBBACA Objective}\label{part-one-chewbbaca-objective}

\begin{itemize}
\tightlist
\item
  To create wgMLST and cgMLST schema for a collection of 200 MRSA \emph{Staphylococcus aureus} genomes (50 complete genomes and 150 draft genomes) from NCBI RefSeq and BVBRC
\end{itemize}

\subsubsection{Activating Conda environment}\label{activating-conda-environment}

Before we begin, the software we need to conduct our analysis have already been installed on your instance using \href{https://docs.conda.io/projects/conda/en/stable/user-guide/install/index.html}{Conda}. However, we need to activate this environment to use the necessary tools.

\begin{verbatim}
# Activate conda environment to use chewBBACA and Prodigal
conda activate chewie
\end{verbatim}

\subsubsection{Create training file using Prodigal}\label{create-training-file-using-prodigal}

ChewBBACA requires a training file to predict genes and proteins for our species of interest. For this purpose, we are going to use the \emph{S. aureus} USA300 reference genome to generate the training file.

\begin{verbatim}
prodigal -i USA300ref.fasta -t Staphylococcus_aureus.trn -p single
\end{verbatim}

\subsubsection{Create wgMLST schema using the complete genomes from NCBI}\label{create-wgmlst-schema-using-the-complete-genomes-from-ncbi}

Now that we have our training file, we will start by creating a whole-genome multi-locus sequence typing (wgMLST) schema based on the complete 50 \emph{S. aureus} genomes from NCBI RefSeq

\begin{verbatim}
chewBBACA.py CreateSchema -i genomes/NCBI-RefSeq-50 -o mrsa_schema --ptf Staphylococcus_aureus.trn --cpu 4
\end{verbatim}

This will use the prodigal training file to identify CDS from the complete set of S. aureus genomes in NCBI and save them in the mrsa\_schema folder

\begin{quote}
The schema seed will be found in that folder with 3,389 identified loci.
\end{quote}

\subsubsection{Allele Calling}\label{allele-calling}

Next is to perform allele calling with the wgMLST schema that we created in the previous step.

This will determine the allelic profiles of the strains we are analyzing by identifying novel alleles, which will be added to the schema.

\begin{verbatim}
chewBBACA.py AlleleCall -i genomes/NCBI-RefSeq-50 -g mrsa_schema/schema_seed -o wgMLST_50 --cpu 4
\end{verbatim}

\begin{quote}
Using a BLAST score ratio (BSR) of 0.6 and clustering similarity of 0.2, 13,762 novel alleles were identified, bringing the number of alleles in the schema to 17,151.
\end{quote}

\subsubsection{Paralog Detection}\label{paralog-detection}

If you noticed from the previous results, 13 paralogs were identified. You can also find them in the \texttt{paralogous\_counts.tsv} in the wgMLST\_50 folder. It is important to remove these paralogs from the schema due to their uncertainty in allele calls. To do this run the following

\begin{verbatim}
chewBBACA.py RemoveGenes -i wgMLST_50/results_alleles.tsv -g wgMLST_50/paralogous_counts.tsv -o wgMLST_50/results_alleles_NoParalogs.tsv
\end{verbatim}

\begin{quote}
By doing this, the new allelic profile without the paralogs are now saved in \texttt{results\_alleles\_NoParalogs.tsv}, which encompasses 3,376 loci
\end{quote}

\subsubsection{cgMLST schema analysis}\label{cgmlst-schema-analysis}

After some QC, we can now determine how many loci are present in the core genome based on the allele calling results. This is based on a given threshold of loci presence in the genomes we analyzed. The ExtractCgMLST module uses 95\%, 99\%, and 100\% to determine the set of loci in the core genome.

\begin{verbatim}
chewBBACA.py ExtractCgMLST -i wgMLST_50/results_alleles_NoParalogs.tsv -o wgMLST_50/cgMLST
\end{verbatim}

If you look in the cgMLST folder, there is an interactive HTML line plot showing the cgMLST per threshold relative to the number of loci detected.

\begin{quote}
From the plot, how many loci are present in the core genome at 95\%? We would use this threshold to account for loci that might not be identified due to sequencing coverage and assembly issues.
\end{quote}

\subsubsection{cgMLST assignment for 150 genomes}\label{cgmlst-assignment-for-150-genomes}

These are 150 MRSA genomes with good quality from Australia pulled from BVBRC with associated metadata. Mislaballed species have been excluded.

\begin{quote}
Using the 1,999 loci found in 95\% core genomes, we will perfome Allele assignment on the 150 genomes
\end{quote}

\begin{verbatim}
chewBBACA.py AlleleCall -i genomes/BVBRC-150 -g mrsa_schema/schema_seed --gl wgMLST_50/cgMLST/cgMLSTschema95.txt -o BVBRC-150_results --cpu 4
\end{verbatim}

\begin{quote}
At the end of the analysis, this added 13,244 novel alleles to the schema with no paralogs
\end{quote}

\subsubsection{Convert Allele Calls}\label{convert-allele-calls}

To convert the allelic profiles into a suitable format that can be parsed into other tools, we need to convert the non-integers such as INF, ASM, PLOT3, and PLOT5 into integars

\begin{verbatim}
chewBBACA.py ExtractCgMLST -i BVBRC-150_results/results_alleles.tsv -o BVBRC-150_results/cgMLST-150
\end{verbatim}

\subsection{PART TWO: cgMLST clustering Objective}\label{part-two-cgmlst-clustering-objective}

The purpose of this lab session is to take the cgMLST allele assignment that we have previously generated with chewBBACA and cluster them using Hamming distance matrix and allele thresholds. In addition, we would visualize our dataset using a dendrogram and annotate it with our cluster threshold and associated metadata.

The overall goal is to infer genetic relatedness in our dataset by leveraging computational tools to investigate potential outbreaks and their potential sources.

\subsubsection{Getting Started}\label{getting-started}

We will begin by installing the necessary packages and helper script that we need to analyze our data.

Every time you begin a new R session, you must reload all the packages and scripts!

\begin{verbatim}
# install packages requiring BiocManager 

if (!requireNamespace('BiocManager', quietly = TRUE))
    install.packages('BiocManager')

if (!requireNamespace('ComplexHeatmap', quietly = TRUE))
    BiocManager::install('ComplexHeatmap')

if (!requireNamespace('treedataverse', quietly = TRUE))
    BiocManager::install("YuLab-SMU/treedataverse")

# install other packages

required_packages <- c("tidyverse", "data.table", "BiocManager", "plotly", "ggnewscale", "circlize",
                      "randomcoloR", "phangorn", "knitr", "purrr", "scales", "remotes","reactable",
                      "ggtreeExtra")

not_installed <- required_packages[!required_packages %in% installed.packages()[,"Package"]]

if (length(not_installed) > 0) {
  install.packages(not_installed, quiet = TRUE)
}


# load packages 

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(treedataverse))
suppressPackageStartupMessages(library(plotly))
suppressPackageStartupMessages(library(ggnewscale))
suppressPackageStartupMessages(library(ComplexHeatmap))
suppressPackageStartupMessages(library(circlize))
suppressPackageStartupMessages(library(randomcoloR))
suppressPackageStartupMessages(library(RColorBrewer))
suppressPackageStartupMessages(library(phangorn))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(scales))
suppressPackageStartupMessages(library(reactable))
suppressPackageStartupMessages(library(ggnewscale))
suppressPackageStartupMessages(library(ggtreeExtra))

## source helper R scripts
source("src/ggtree_helper.R")
source("src/cluster_count_helper.R")
source("src/cluster_helper.R")
source("src/cgmlst_helper.R")
\end{verbatim}

Next read the cgMLST data from chewBBACA and the metadata into memory

\begin{verbatim}
# read cgMLST and metadata
aus_mrsa_cgMLST <- read.delim("BVBRC-150_results/cgMLST-150/cgMLST95.tsv", sep = "\t")

mrsa.data <- read.csv("MRSA_AUS_metadata.csv", header = F)
\end{verbatim}

Having loaded our files, we need to make some adjustments to our metadata to make it suitable for our analysis.

\begin{quote}
first, we are going to change the header,
then we are going to create a new column for the host to exclude the taxon ID
\end{quote}

\begin{verbatim}
# change the header of the metadata file
new.header <- mrsa.data[2,]
aus_mrsa_metadata <- mrsa.data[-c(1,2),]
colnames(aus_mrsa_metadata) <- new.header

head(aus_mrsa_metadata)

aus_mrsa_metadata_reordered <- aus_mrsa_metadata %>% 
  select(6, everything()) # move 6th column to the first position

head(aus_mrsa_metadata_reordered)

# Create a new Host column with just the host name
aus_mrsa_metadata_reordered <- aus_mrsa_metadata_reordered %>%
  mutate(Host = str_remove(`host (common name)`, "\\s*\\[.*\\]"))
\end{verbatim}

\begin{quote}
Can you spot the differences between the two metadata? Which one do you think we are going to use?
\end{quote}

\subsubsection{Calculating the Hamming Distance}\label{calculating-the-hamming-distance}

The traditional approach for cgMLST analysis is based on computing pairwise distances between allele profiles as a proxy for the underlying genetic similarity between two isolates. Below, you are introduced to a distance metric called the \textbf{Hamming distance}, which is based on computing the number of differences between a pair of character vectors. The Hamming distance is useful for comparing profiles where a majority of characters are defined, such as profiles comprising core loci.

Given two character vectors of equal lengths, the Hamming distance is the total number of positions in which the two vectors are \ul{different:}

Profile A: \texttt{{[}\ 0\ ,\ 2\ ,\ 0\ ,\ 5\ ,\ 5\ ,\ 0\ ,\ 0\ ,\ 0\ ,\ 0\ {]}}

Profile B: \texttt{{[}\ 0\ ,\ 1\ ,\ 0\ ,\ 4\ ,\ 3\ ,\ 0\ ,\ 0\ ,\ 0\ ,\ 0\ {]}}

~~A != B: \texttt{{[}\ 0\ ,\ 1\ ,\ 0\ ,\ 1\ ,\ 1\ ,\ 0\ ,\ 0\ ,\ 0\ ,\ 0\ {]}} ~~

Hamming distance = \texttt{sum(\ A\ !=\ B\ )} = 3

\begin{quote}
In phylogenetic analysis, distance-based approaches are rather flexible in the sense that they can be constructed from any measure that estimates genetic similarity through the direct comparison of data points. In cgMLST, we compare allele profiles. In Mash, we compare k-mer profiles.
\end{quote}

In the context of two cgMLST profiles, the Hamming distance is calculated based on the number of allele differences across all loci as a proportion of total number of loci evaluated.

Hamming distances will be computed in an \emph{all vs.~all} fashion to generate a pairwise distance matrix that will subsequently serve as the input for distance-based tree-building algorithms. Run the following code chunk:

\begin{verbatim}
# use hamming helper function to compute pairwise Hamming distance of cgMLST data 

# compute Hamming distance 
# PATIENCE!!! this step might take several minutes depending on the size of the dataset

mrsa.dist_mat <- aus_mrsa_cgMLST %>% 
  column_to_rownames("FILE") %>% 
  t() %>% 
  hamming()

# the dimension should be symmetric and should be the size of dataset (i.e. number of QC-passed genomes)

dim(mrsa.dist_mat)

\end{verbatim}

\subsubsection{Hierarchical Clustering of cgMLST profiles by Hamming distance}\label{hierarchical-clustering-of-cgmlst-profiles-by-hamming-distance}

In this section we will be performing hierarchical clustering of the Hamming distance matrix using the \href{https://en.wikipedia.org/wiki/UPGMA}{Unweighted Pair Group Method with Arithmetic Mean} (i.e.~\textbf{UPGMA}) algorithm.

Let's cluster the Hamming distance matrix by running the code chunk below:

\begin{verbatim}
#  compute hierarchical clustering with hclust function and complete linkage method

mrsa.hc <- mrsa.dist_mat%>%
        as.dist() %>%
         hclust(method = "complete")

# reorder distance matrix according to the hc order 

mrsa.dist_mat <- mrsa.dist_mat[mrsa.hc$order, mrsa.hc$order]

# write reordered  distance matrix to files 
dir.create("output/clusters", recursive = T)
write.table(mrsa.dist_mat, file = "output/clusters/dist_mat_ordered_cgmlst.tsv",
             quote = F, row.names = F, sep = "\t")
             
\end{verbatim}

\subsubsection{Cluster extraction at multiple distance thresholds}\label{cluster-extraction-at-multiple-distance-thresholds}

Identifying clusters of genomes sharing highly similar cgMLST profiles through the application of distance thresholds is a common practice in genomic surveillance and epidemiological investigations. These genomic clusters can become ``analytical units'' that can be tracked across space and time:

\begin{itemize}
\tightlist
\item
  The detection of a novel genomic cluster comprising isolates from multiple human clinical cases can signal the emergence of an outbreak, thus requiring a public health response in order to contain further cases.\\
\item
  An examination of the evolving genomic cluster over time can provide important epidemiological insights on outbreak progression.
\item
  The co-clustering of outbreak isolates with isolates from food/environmental sources can assist epidemiologists investigating an outbreak by linking the outbreak isolates to isolates from possible sources/reservoirs of the pathogen.
\end{itemize}

Identifying cluster membership for every isolate in the dataset at multiple distance thresholds gives us the analytical flexibility to define suitable thresholds for analyzing the pathogen in question. From a practical perspective, a threshold that is too fine-grained will yield a large proportion of the dataset in singleton clusters, making it difficult to link outbreak isolates to one another and to potential outbreak sources. Conversely, using a threshold that is not fine-grained enough will fail to fully exploit the discriminatory power of genomic data, grouping outbreak and non-outbreak isolates indiscriminately.

\begin{quote}
Adjusting similarity thresholds for cluster membership can be used to tweak the granularity of clusters: higher distance threshold produce larger clusters whereas lower distance thresholds will produce smaller clusters. A threshold of 0 will generate clusters with \textbf{identical} profiles.
\end{quote}

\textbf{For membership at all possible distance thresholds}, run the following code chunk:

\begin{verbatim}

# Define genomic cluster membership at all possible distance thresholds

mrsa.cgmlst_loci = (ncol(aus_mrsa_cgMLST)-1) ## maximum distance 
interval = 1  ##  edit interval of interest; currently set to 1 then change to 10 to see how many thresholds are generated

threshld <-  seq(0, mrsa.cgmlst_loci,interval)


# extract cluster membership across multiple thresholds
cluster_group <- map(threshld, function(x) {
    mrsa.hc %>% 
    cutree(h = x) %>% 
    as.factor()
})

# create name for each threshold
names(cluster_group) <- paste0("Threshold_", threshld)


# print clustering results table, no duplicated names are allowed
 (
all.clusters <- data.frame(cluster_group ) %>%
    rownames_to_column("FILE")
 )  

# reactable(clusters_all)

# write file of genomic cluster memberships at multiple thresholds
write.table(all.clusters, file = "output/clusters/clusters_all.tsv",
            quote = F, row.names = F, sep = "\t")
\end{verbatim}

\begin{quote}
\textbf{Questions:} How many distinct thresholds are theoretically possible for this dataset? How would you determine the maximum number of allele differences across all genomes in the dataset based on the table above? \emph{hint: at some threshold, all genomes collapse to the same cluster\ldots{}}
\end{quote}

\textbf{For membership at select distance thresholds}, run the following code chunk:

\begin{verbatim}
# Define genomic cluster membership at user-defined distance thresholds

# Can either specify specific thresholds as a numeric vector i.e. c(0, 5, 10, 15) 
# If you're feeling lazy, you can also specify using c(seq(5, 100, 5)), which stands for "go from threshold 5 to 100 in
# increments of 5". You can also string multiple notations together within the same numerical vector.  

threshld <-c(0, seq(5, 100, 5), seq(200, mrsa.cgmlst_loci, 100))   # currently reads as "use threshold 0, 
                                                                # then from 5 to 100 in increments of 5
                                                                # then from 200 to maximum threshold 
                                                                # in increments of 100"

# extract cluster membership across multiple thresholds
 cluster_group <- map(threshld, function(x) {
     mrsa.hc %>%
     cutree(h = x) %>%
     as.factor()
 })

# create name for each threshold
 names(cluster_group) <- paste0("Threshold_", threshld)

# print clustering results table, no duplicated names are allowed
 (
   new_defined_clusters <- data.frame(cluster_group ) %>%
     rownames_to_column("FILE")
   )

# write file
 write.table(new_defined_clusters, file = "output/clusters/new_defined_clusters.tsv",
             quote = F, row.names = F, sep = "\t")

\end{verbatim}

\begin{quote}
\textbf{Questions:} How many user-defined thresholds have we generated in the settings provided here? Which cluster does genome ``1280\_21738'' belong to at a threshold of 25 allele differences? How would you determine how many different clusters were generated at each particular threshold?
\end{quote}

\subsubsection{Distance matrix visulization via ordered heatmap}\label{distance-matrix-visulization-via-ordered-heatmap}

A very useful visualization when dealing with distance matrices involves performing clustering, arranging the entries of the matrix based on the clustering order, and displaying the similarity as a heatmap. This produces a heatmap with a distinct 45 degree axis in which clusters of profiles with significant similarity representing possible clades/lineages can be plainly seen as ``pockets of heat''. In this section of the lab, we will visualize the distance matrix using the \texttt{ComplexHeatmap} package and we will be comparing these clades to the MLST genotype information on the isolates by overlaying MLST information on the heatmap, which will allow us to examine whether the organism's MLST is concordant with putative lineages defined by cgMLST similarity as displayed on the clustered heatmap.

Let's run the code chunk below:

\begin{verbatim}
# create column annotations for heatmap
# to display clade information
set.seed(123)

htmap_annot <-  aus_mrsa_metadata_reordered$genotype
names(htmap_annot) <-aus_mrsa_metadata$`BV-BRC genome ID`

htmap_annot <- htmap_annot[order(factor(names(htmap_annot),
                                            levels = rownames(mrsa.dist_mat)))]

# create heatmap
mrsa.dist_mat %>% 
  Heatmap(
    name = "cgMLST\nDistance",
    show_row_names = F, # do not display row labels
    show_column_names = F, # do not display column labels
    # use custom color gradient
    col = colorRamp2(
      c(min(mrsa.dist_mat), mean(mrsa.dist_mat), max(mrsa.dist_mat)),
      c("#f76c6a", "#eebd32", "#7ece97")
    ),
    # add column annotation to show MLST info overlaid on the clustered heatmap
    top_annotation = HeatmapAnnotation(
      MLST= htmap_annot,
      col = list(
      MLST = structure(brewer.pal(length(unique(htmap_annot)), "Set3"),
                                             names = unique(htmap_annot))
      )
    )
    
  )
\end{verbatim}

\subsubsection{Annotated Dendrograms and cluster evaluation}\label{annotated-dendrograms-and-cluster-evaluation}

Here you will convert hierarchical clustering result (mrsa.hc) into a dendrogram using the \texttt{as.phylo()} function from the ape package. To visualize the resulting dendrogram, we will use the R package \texttt{ggtree}, which offers an extensive suite of functions to manipulate, visualize, and annotate tree-like data structures. In this section, you will be introduced to some of the different visual capabilities of \texttt{ggtree} and we will progressively update the same tree with several layers of visual annotations based on available metadata.

\begin{quote}
Note that there is a massive amount of information in the internet dedicated to \texttt{ggtree} and all of its capabilities for advanced visualizations. Here we will barely scratch the surface.
\end{quote}

\subsubsection{Circular vs.~Rectangular dendrograms for simple tree visualization}\label{circular-vs.-rectangular-dendrograms-for-simple-tree-visualization}

Radial vs.~Rectangular dendrograms are different ways of visualizing a tree. Radial trees are capable of displaying a lot of simple data in a smaller footprint. In contrast, rectangular trees can display more complex data in a visualization that is easy on the eyes. Rectangular trees rendered as pdf format allow you to really zoom into sub-branches of the tree in greater detail when viewed in a pdf reader or in a browser window. This is essential when you're dealing with larger datasets comprising hundreds of isolates such as the one we are dealing with here.

Run the following code chunks to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Plot a circular tree of the entire dataset with the tree tips colored by MLST information. \emph{You can assign a different metadata field to the \texttt{color\_var} variable to update the mapping of the color aesthetics in the tree. For example setting \texttt{color\_var\ =\ "Host"} will color the tree tips by source of isolate}.
\item
  Plot the same tree as a rectangular tree.
\end{enumerate}

\begin{verbatim}
# convert hierarchical clustering to a dendrogram 
set.seed(123)
mrsa.cg_tree <- as.phylo(mrsa.hc)

# also, write out the dendrogram to a Newick tree file, can be imported into ITOL or other tree visualization software for manual annotation
dir.create("output/trees", recursive = T)
write.tree(mrsa.cg_tree, file = "output/trees/tree_complete_linkage.newick")

# visualization with a color variable using R ggtree 
color_var <- "genotype" # editable variable, currently set to "MLST".

## filter out unknown serotypes to define the number of colors needed for remaining serotypes 
n_colors <- length(unique(pull(aus_mrsa_metadata_reordered, !!sym(color_var))))

## create circular dendrogram with variable-colored tippoints
cg_tree_cir <- mrsa.cg_tree %>% 
  ggtree(layout='circular', # set tree shape 
         size = 1 # branch width
  )%<+% aus_mrsa_metadata_reordered +
  geom_tippoint(aes(color = as.factor(!!sym(color_var))),
                size = 2,na.rm=TRUE) +
  guides(color = guide_legend(title = "MLST", override.aes = list(size = 3) ) ) +
  scale_color_manual(values = distinctColorPalette(n_colors),na.value = "grey") 

cg_tree_cir


# Create rectangular tree with MLST tip points and text tip labels

# create tip labels 
aus_mrsa_metadata_reordered <- aus_mrsa_metadata_reordered %>%
            mutate(tip_lab = paste0(Host,"/ ",sample_collection_date))

## plot    
set.seed(123)
  mrsa.cg_tree %>% 
  ggtree(layout= "rectangular")%<+% aus_mrsa_metadata_reordered +
  geom_tippoint(aes(color = as.factor(!!sym(color_var))),
                size = 3,na.rm=TRUE) +
  geom_tiplab(aes(label = tip_lab),  
              offset = 5,
              align = TRUE,
              linetype = NULL,
              size = 3) +theme_tree2()+
  geom_treescale(y = 130, x = 0.2) +
  guides(color = guide_legend(title = "MLST", override.aes = list(size = 3) ) ) +
  scale_color_manual(values = distinctColorPalette(n_colors))
  
 # We save to pdf format
 ggsave(file = "output/trees/clade_subtree_rec.pdf", height = 45, width = 40) 
 
\end{verbatim}

\begin{quote}
\textbf{Questions:} Between ST22 and ST93, which one shows more heterogeneity based on the cgMLST data?
\end{quote}

\subsubsection{Superimposing genomic cluster information onto dendrograms}\label{superimposing-genomic-cluster-information-onto-dendrograms}

Let's now superimpose the genomic cluster information on the previous dendrograms (Radial \& Rectangular) to examine whether the above code chunk for extracting cluster memberships at various thresholds has generated sensible cluster assignments. Run the code chunk below to insert text labels that span across tree tips assigned to the same clusters at \ul{a specified threshold}. Interchange your threshold to 50 and 15 and see how it affects your cluster outcome.

\begin{quote}
You can edit the \texttt{target\_threshold} variable to examine how cluster membership changes in response to clustering distance cutoffs.
\end{quote}

Run the code chunk below for the radial tree:

\begin{verbatim}
# Radial tree visualization

# assign all clusters to clusters for visualization  
mrsa.clusters <- all.clusters 

target_threshold <- 25 # Editable variable,  currently set to a threshold of 25.

aus_mrsa_metadata_reordered <- aus_mrsa_metadata_reordered %>%
             select(-tip_lab)

# variable to subset clusters
target_variable <- paste0("Threshold_", target_threshold)

# create cluster group list object
cluster_grp <- mrsa.clusters %>% 
  select(FILE, target_variable) %>%
  group_by(!!sym(target_variable)) %>% 
  {setNames(group_split(.), group_keys(.)[[1]])} %>% 
  map(~pull(., FILE))
# sequester singleton clusters
cluster_grp <- cluster_grp[which(map_dbl(cluster_grp, ~length(.)) > 10)]

# create clade group list object
meta2 <- aus_mrsa_metadata_reordered %>%
         filter(genotype != "unknown")
Clade_grp <- meta2 %>% 
  select(`BV-BRC genome ID`, genotype) %>% 
  split(f = as.factor(.$genotype)) %>% 
  map(~pull(., `BV-BRC genome ID`))

# add cluster memberships and clade information to tree object
mrsa.cg_tree <- groupOTU(mrsa.cg_tree, cluster_grp, 'Clusters')
mrsa.cg_tree <- groupOTU(mrsa.cg_tree, Clade_grp, 'MLST')

# plot core genome tree where colored blocks = clusters and text annotations = clades
valid_clade_grp <- Clade_grp %>%
  keep(~all(.x %in% mrsa.cg_tree$tip.label)) %>%
  keep(~length(.x) > 1)  # Need at least 2 tips for MRCA

valid_cluster_grp <- cluster_grp %>%
  keep(~all(.x %in% mrsa.cg_tree$tip.label)) %>%
  keep(~length(.x) > 1)

mlst.t25 <- mrsa.cg_tree %>% 
  ggtree(layout='circular', # Editable tree shape, currently set to circular?
         size = 1 # branch width
  ) +
 
  # add colored blocks to display clades
  geom_hilight(
    mapping = aes(
      node = node,
      fill = MLST,
      subset = node %in% map_dbl(
        valid_clade_grp,
        ~getMRCA(mrsa.cg_tree, .)
        )
      )
    ) +
  #add text annotations to display clusters
  geom_cladelab(
    mapping = aes(
      node = node,
      label = Clusters,
      subset = node %in% map_dbl(
        valid_cluster_grp,
        ~ getMRCA(mrsa.cg_tree, .)
      )
    ),
    horizontal=T,
    angle = 'auto',
    barsize = 0.75,
    offset = 50,
    offset.text = 50,
    align = T
  ) +
  # legend parameters
  guides(fill = guide_legend(
    nrow = 11,
    override.aes = list(alpha = 0.8)
    )
  ) +
  labs(fill = "MLST") +
  scale_fill_brewer(palette = "Paired")

mlst.t25
\end{verbatim}

\begin{verbatim}
final_plot <- mlst.t25 %<+% aus_mrsa_metadata_reordered +
  geom_tippoint(aes(color = Host), size =2) +
    scale_colour_manual(name = "Host", values = c("#008080","#ffa500","#00ff00","#0000ff","#ff1493"))

final_plot
\end{verbatim}

Here we can see a couple of things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The cgMLST cluster threshold of 25 allele differences has more discriminatory power than MLST for investigating putative outbreaks or inferring genetic similarity
\item
  Cluster 50 comprises of mostly horse isolates and two human isolates
\item
  We can infer the directionality of the outbreak in cluster 50 by looking at the sample collection dates and location if the data are present
\end{enumerate}

\begin{verbatim}
ggsave("Threshold25_clusters.pdf", plot = final_plot, height = 10, width = 8, device = "pdf")

\end{verbatim}

\textbf{Congratulations!} You have successfully completed Module 3.

\chapter{Module 4 Outbreak Analysis}\label{module-4-outbreak-analysis}

\emph{Author: Finlay Maguire}

\emph{Last Modified: 2025-11-11}

\section{Lecture}\label{lecture-3}

Link to PDF of slides from google

\section{Lab}\label{lab-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \hyperref[intro]{Background}
\item
  \hyperref[setup]{Setup}
\item
  \hyperref[cluster]{Cluster Identification}
\item
  \hyperref[snp]{SNP Analysis}
\item
  \hyperref[trans]{Transmission Inference}
\end{enumerate}

In this lab practical we will be using microbial genomes (and associated contextual metadata) to investigate a suspected nosocomial (hospital-acquired) outbreak of \emph{Methicillin resistance Staphylococcus aureus} (MRSA) in a UK-based Neonatal Intensive Care Unit (NICU). The data we are using comes from a classic study which demonstrated the utility of whole genome sequencing for investigating an MRSA outbreak within a Special Care Baby Unit (also known as a NICU) of the Cambridge University Hospitals NHS Foundation Trust (CUH).

\begin{quote}
Harris SR, Cartwright EJP, Török ME, et al.~Whole-genome sequencing for analysis of an outbreak of methicillin-resistant Staphylococcus aureus: a descriptive study. \emph{Lancet Infect Dis} 2012 \href{http://dx.doi.org/10.1016/S1473-3099(12)70268-2}{10.1016/S1473-3099(12)70268-2}
\end{quote}

This practical will step you through the genomic components of a typical nosocomial bacterial outbreak investigation, specifically:

\begin{itemize}
\tightlist
\item
  Identifying potential outbreak clusters
\item
  Determining SNP distances
\item
  Inferring outbreak phylogenies
\item
  Performing transmission inference
\end{itemize}

\subsection{Background}\label{background}

\emph{Staphylococcus aureus} is a Gram-positive coccoidal bacteria that forms a normal commensal member of the microbiome in 20-40\% of people (\href{https://doi.org/10.1016/j.ijmm.2016.11.007}{Karsten, 2017}). However, when skin and mucosal barriers are disrupted (e.g., through medical procedures such as catheterisation, tracheal tubes, surgeries) \emph{S. aureus} can cause opportunistic invasive infections (\href{https://doi.org/10.1038/nrdp.2018.33}{Lee, 2018}).

Since the 1960s, variants have emerged and spread globally that are resistant to the majority of β-lactam antibiotics through the independent acquisitions of the staphylococcal cassette chromosome mec (SCCmec) (\href{https://doi.org/10.1128/AAC.00579-09}{IWG-SSC, 2009}. This combination of commensal carriage, antimicrobial resistance, and healthcare-associated infection opportunities (along with additional virulence factors) have led to MRSA becoming a leading cause of hospital-associated mortality and morbidity globally (\href{https://doi.org/10.1016/s0140-6736(24)01867-1}{GBD, 2024}). Therefore, tracking and preventing MRSA outbreaks is a major priority for infection prevention and control (IPAC or IPC) within hospital settings especially within the NICU due to the vulnerability of immunocompromised preterm infants and the high frequency of invasive procedures.
This has led to adoption of genomic epidemiological approaches to detect MRSA outbreaks and track transmission links not apparent from traditional approaches alone (\href{https://doi.org/10.1099/mgen.0.001235}{Blane, 2024}). These sort of outbreak investigations are generally led by the infection prevention \& control (IPAC or IPC) team in a clinical setting or by the relevant public health team depending on the suspected infection source, geographic scale, and regional resource availability (e.g., Public Health Agency of Canada/Canadian Food Inspection Agency or provincial bodies like Public Health Ontario).

Within the SCBU/NICU of Cambridge University Hopitals NHS Trust (and most hospitals) all inpatients are screened for MRSA carriage upon admission and once per week thereafter using culture-based or nucleic-acid based test. Specific IPAC policies and guidelines will determine criteria for initiating an outbreak investigation (e.g., a certain number of positive screens within a specific time and/or location).

Routine surveillance has identified that 3 infants within the SCBU/NICU (P11-P13) are positive for MRSA carriage at the same time. Isolates from these 3 infants have also been shown to have the same pattern of antibiotic resistances. The IPAC team has therefore been activated to further investigate this as a suspected outbreak in the SCBU/NICU at CUH.
They have performed a systematic review of all MRSA isolates from the SCBU/NICU over the preceding 6-12 months and identified a series of overlapping MRSA carriages with this same set of resistances. Due to multi-week gaps in the positive SCBU/NICU isolates they have also collected potentially matching MRSA isolates from parents and the wider hospital/community. To gain better insight into this potential outbreak and identify which of these isolates are linked by direct transmission chains, CUH have sequenced these isolates using 150bp paired-end reads via an Illumina MiSeq platform.

You are a clinical bioinformatician who has been asked to support the investigation and analyses these genomes

\subsection{Set-Up}\label{set-up}

This lab practical will involve running the following software:

\begin{itemize}
\tightlist
\item
  \href{https://github.com/tseemann/mlst}{mlst}
\item
  \href{https://github.com/bacpop/PopPUNK}{poppunk}
\item
  \href{https://github.com/bacpop/ska.rust}{ska}
\item
  \href{https://github.com/nickjcroucher/gubbins}{gubbins}
\item
  \href{https://github.com/iqtree/iqtree3}{IQTree}
\item
  \href{https://graphsnp.fordelab.com/}{GraphSNP}
\end{itemize}

Typically, most of these analyses would be run using a workflow such as \href{https://bactopia.github.io/latest/}{bactopia} that you are confident will reproducibly generate validated and verified outputs (ideally as part of your institution's ISO15189 accreditation or equivalent). We will run the tools directly today so you get insight into what these workflows are actually doing!

\subsubsection{Data}\label{data}

Using ssh connect to the provided analysis server instance:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ssh} \AttributeTok{{-}i}\NormalTok{ YOUR\_KEY.pem YOUR\_USER@XX.uhn{-}hpc.ca}
\end{Highlighting}
\end{Shaded}

Now create a folder in your \texttt{\textasciitilde{}/workspace} and copy/link over the files you will need:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mkdir} \AttributeTok{{-}p}\NormalTok{ \textasciitilde{}/workspace/module4}
\BuiltInTok{cd}\NormalTok{ \textasciitilde{}/workspace/module4}
\FunctionTok{cp} \AttributeTok{{-}r}\NormalTok{ \textasciitilde{}/CourseData/module4/contextual\_data.csv  \textasciitilde{}/CourseData/module4/SASCBU26\_reference.fna .}
\FunctionTok{ln} \AttributeTok{{-}s}\NormalTok{ \textasciitilde{}/CourseData/module4/assemblies .}
\end{Highlighting}
\end{Shaded}

Specific collection dates were not available so have been inferred based on relative sampling gaps

When you are finished with these steps you should be inside your work directory \texttt{\textasciitilde{}/workspace/module4}. You can verify this by running the command \texttt{pwd}.
s
\textbf{Output after running \texttt{pwd}}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\textasciitilde{}/workspace/module4}
\end{Highlighting}
\end{Shaded}

You now see an \texttt{assemblies/} folder in the current directory along with a \texttt{contextual\_metadata.tsv} (all the contextual data needed for this analysis) and \texttt{SASCBU26\_reference.fna} (the reference genome we will use later):

\textbf{Output after running \texttt{ls}}s

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{SASCBU26\_reference.fna}\NormalTok{  assemblies  contextual\_data.csv}
\end{Highlighting}
\end{Shaded}

\subsubsection{Activate environment}\label{activate-environment}

Next we will activate the pre-installed \href{https://docs.conda.io/en/latest/}{conda} environment, which will have all the tools needed by this tutorial pre-installed. To do this please run the following:

\textbf{Commands}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{conda}\NormalTok{ activate outbreak}
\end{Highlighting}
\end{Shaded}

You should see the command-prompt (where you type commands) switch to include \texttt{(outbreak)} at the beginning, showing you are inside this environment. You should also be able to run the \texttt{mlst} command like \texttt{mlst\ -\/-version} and see output:

\textbf{Output after running \texttt{mlst\ -\/-version}}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{mlst}\NormalTok{ 2.23.0}
\end{Highlighting}
\end{Shaded}

\subsubsection{Find your IP address}\label{find-your-ip-address}

Similar to yesterday, we will want to either use the assigned hostname (e.g., xx.uhn-hpc.ca where xx is your instance number) or find the IP address of your machine on AWS so we can access some files from your machine on the web browser. To find your IP address you can run:

\textbf{Commands}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{curl}\NormalTok{ http://checkip.amazonaws.com}
\end{Highlighting}
\end{Shaded}

This should print a number like XX.XX.XX.XX. Once you have your address, try going to \url{http://xx.uhn-hpc.ca} or \url{http://IP-ADDRESS} and clicking the link for \textbf{module4}. This page will be referred to later to easily download/view some of our output files.

\subsection{Cluster Identification}\label{cluster-identification}

All isolates that are putatively linked to the outbreak have been done so on the basis of time, location, and phenotype (specifically antibiotic susceptibilities). However, just because 2 isolates have the same resistance pattern does not mean they are closely related.
Although this is a relatively small set of isolates we are often evaluating very large numbers of genomes for their potential connection to an outbreak.
Additionally, most downstream outbreak analyses (such as transmission inference) perform best when applied to as little diversity as possible (i.e., just genomes from a single outbreak event).

This means our first task is to identify and group which isolates are actually connect

are likely to be linked using the sort of typing methods you encountered in the previous lab practical.
This helps us to eliminate unrelated genomes and determine whether 1 or more outbreaks are likely to be taking place.

To make things faster for this practical, we have provided pre-inferred genome assemblies (generated using \href{https://github.com/tseemann/shovill}{shovill} with the \href{https://github.com/ncbi/SKESA}{skesa} assembler).

You can infer the 7-gene MLST using the \href{https://pubmlst.org/organisms/staphylococcus-aureus}{pubMLST \emph{Staphylococcus aureus} scheme} by running the \texttt{mlst} tool on each of the genome assemblies.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mkdir} \AttributeTok{{-}p}\NormalTok{ outbreak\_cluster\_identification}\KeywordTok{;} \BuiltInTok{cd}\NormalTok{ outbreak\_cluster\_identification}
\ExtensionTok{mlst} \AttributeTok{{-}{-}scheme}\NormalTok{ saureus ../assemblies/}\PreprocessorTok{*}\NormalTok{.fa }\OperatorTok{\textgreater{}}\NormalTok{ mlst.tsv}
\end{Highlighting}
\end{Shaded}

Now download the \texttt{mlst.tsv} output file (using either \texttt{scp} or the IP address listed above) and open it in your tabular data tool of choice (e.g., pandas/python, R, excel).

\textbf{Based on these results, which genomes do you suspect may not be part of this outbreak?}

\begin{itemize}
\tightlist
\item
  P27 \& P28 have different MLSTs (ST1 and ST8) to any other genome so unlikely to be linked to an outbreak.
\item
  P29 \& P34-38 (with P37 a partial match) could be an ST22 outbreak.
\item
  P30-33 could be an ST772 outbreak.
\item
  All remaining isolates belong to a large ST2731 set
\end{itemize}

\textbf{Why might genomes with a different MLST still be closely related or those with the same MLST be relatively unrelated?}

MLST are only 7 genes so a small amount of mutation (or conservation!) in just these genes can lead to a totally different MLST - schemes are designed to try and be robust but are mutation is a random process with high variance!

We could solve this challenge using a more fine-grained scheme like cg/wgMLST (as discussed in the previous module) but we are going to use \texttt{poppunk} in this lab.

\texttt{poppunk} is a rapid k-mer based genome clustering tool that groups genomes together based on both their core and accessory genome distances. This allows differential clustering of similar genomes which have acquired novel plasmids and so on.

The developers of poppunk provide some pre-computed databases (although it is relatively easy to create your own) for different species which are available \href{https://www.bacpop.org/poppunk-databases/}{here}.

We have already downloaded a reference database for you, so all you have to do is prepare a 2-column file \texttt{genomes.txt} which has a series of names in the first column and the path to the related genome assembly in the other.
We can do this using a quick bash one-line loop:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ ../assemblies/}\PreprocessorTok{*}\NormalTok{.fa}\KeywordTok{;} \ControlFlowTok{do} \VariableTok{isolate}\OperatorTok{=}\VariableTok{$(}\BuiltInTok{echo} \VariableTok{$i} \KeywordTok{|} \FunctionTok{cut} \AttributeTok{{-}d} \StringTok{\textquotesingle{}/\textquotesingle{}} \AttributeTok{{-}f3} \KeywordTok{|} \FunctionTok{cut} \AttributeTok{{-}d} \StringTok{\textquotesingle{}.\textquotesingle{}} \AttributeTok{{-}f1}\VariableTok{)}\KeywordTok{;} \BuiltInTok{echo} \AttributeTok{{-}e} \StringTok{"}\VariableTok{$isolate}\StringTok{\textbackslash{}t}\VariableTok{$i}\StringTok{"} \OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ genomes.txt}\KeywordTok{;} \ControlFlowTok{done}
\end{Highlighting}
\end{Shaded}

Then we can run the following to get poppunk cluster assignments:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{poppunk\_assign} \AttributeTok{{-}{-}db}\NormalTok{ \textasciitilde{}/CourseData/module4/staphylococcus\_aureus\_v1\_full }\AttributeTok{{-}{-}query}\NormalTok{ genomes.txt }\AttributeTok{{-}{-}output}\NormalTok{ poppunk}
\end{Highlighting}
\end{Shaded}

Now download/inspect \texttt{poppunk/poppunk\_clusters.csv} file

\textbf{Which genomes does this analysis suggest should be excluded? Do they match the MLST results?}

P27-28 are assigned to cluster 1 and P30-33 are assigned cluster 12. Remaining samples are assigned to cluster 3.

\begin{itemize}
\tightlist
\item
  P27 and P28 were different singleton STs for MLST that share a few alleles so supports eliminating them
\item
  P30-33 were ST772 so poppunk and MLST agree and support eliminating these samples (although they could be their own distinct outbreak)
\item
  ST22 and ST2731 isolates were both assigned to cluster 3. If we look carefully at the MLST profile for these STs in \texttt{mlst.tsv} we can see that these STs only differ by a single allele (arcC) so could be linked in the main outbreak.
\end{itemize}

We can't be sure about cluster 3 without further analysis but we can drop cluster 1 and 12 for now.

\subsection{SNP Analysis}\label{snp-analysis}

Now that we have eliminated some isolates that are unlikely to be connected to our main outbreak we can do a deeper analysis of the evolutionary relationships between our isolates. For this we are going to perform a phylogenetic analysis. There are several way this could be done:

\begin{itemize}
\tightlist
\item
  Inferring and aligning the core genome of our isolates by running a tool like \texttt{panaroo} on the genome assembly annotation files (generated with \texttt{prokka} or \texttt{bakta}).
\item
  Mapping individual reads against a reference genome with a tool like \texttt{snippy}.
\item
  Mapping SNPs between genomes using \texttt{ska} (then using a reference to order these SNPs)
\end{itemize}

\textbf{For SNP analyses, why might we want use a reference derived from an outbreak isolate instead of standard species reference genome?}

We maximise the number of detectable SNPs by using a reference as close as possible to our other genomes

For this lab, we are going to do the last option using a complete high quality reference genome generated from this outbreak subsequent to the original manuscript: SASCBU26

First let's generate the input file for SKA using the poppunk results

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{cd}\NormalTok{ \textasciitilde{}/workspace/module4}\KeywordTok{;} \FunctionTok{mkdir} \AttributeTok{{-}p}\NormalTok{ ska\_phylogeny}\KeywordTok{;} \BuiltInTok{cd}\NormalTok{ ska\_phylogeny}
\FunctionTok{paste} \OperatorTok{\textless{}(}\FunctionTok{grep} \StringTok{"3$"}\NormalTok{ ../outbreak\_cluster\_identification/poppunk/poppunk\_clusters.csv }\KeywordTok{|} \FunctionTok{cut} \AttributeTok{{-}d,} \AttributeTok{{-}f1}\OperatorTok{)} \OperatorTok{\textless{}(}\FunctionTok{grep} \StringTok{"3$"}\NormalTok{ ../outbreak\_cluster\_identification/poppunk/poppunk\_clusters.csv }\KeywordTok{|} \FunctionTok{cut} \AttributeTok{{-}d,} \AttributeTok{{-}f1} \KeywordTok{|} \FunctionTok{perl} \AttributeTok{{-}ne} \StringTok{\textquotesingle{}chomp; print "../assemblies/$\_.fa\textbackslash{}n"\textquotesingle{}} \OperatorTok{)} \OperatorTok{\textgreater{}}\NormalTok{ ska\_input}
\BuiltInTok{echo} \AttributeTok{{-}e} \StringTok{"SASCBU26\textbackslash{}t../SASCBU26\_reference.fna"} \OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ ska\_input}
\end{Highlighting}
\end{Shaded}

Now we need to generate an SKA index:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{ska}\NormalTok{ build }\AttributeTok{{-}f}\NormalTok{ ska\_input }\AttributeTok{{-}k}\NormalTok{ 31 }\AttributeTok{{-}o}\NormalTok{ ska\_index }\AttributeTok{{-}{-}threads}\NormalTok{ 4}
\end{Highlighting}
\end{Shaded}

Then map these split k-mers against the reference (required to order them for the next step):

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{ska}\NormalTok{ map }\AttributeTok{{-}o}\NormalTok{ ska.aln }\AttributeTok{{-}{-}ambig{-}mask}\NormalTok{ ../SASCBU26\_reference.fna ska\_index.skf}
\end{Highlighting}
\end{Shaded}

This gives us an alignment but due the distorting effects of recombination we typically want to try and remove any potential recombinant sites from the alignment. There are several tools that can help us do this (\texttt{verticall}, \texttt{ClonalFrameML}, \texttt{gubbins}) and today we are going to use \texttt{gubbins}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mkdir} \AttributeTok{{-}p}\NormalTok{ gubbins}
\ExtensionTok{run\_gubbins.py} \AttributeTok{{-}{-}prefix}\NormalTok{ gubbins/gubbins ska.aln}
\ExtensionTok{mask\_gubbins\_aln.py} \AttributeTok{{-}{-}aln}\NormalTok{ ska.aln }\AttributeTok{{-}{-}gff}\NormalTok{ gubbins/gubbins.recombination\_predictions.gff }\AttributeTok{{-}{-}out}\NormalTok{ gubbins.masked.aln}
\end{Highlighting}
\end{Shaded}

Now that we have a masked alignment \texttt{gubbins.masked.aln} we can analyse the SNP network using \href{https://graphsnp.fordelab.com/}{GraphSNP} to further refine our potential outbreak samples. First, generate a SNP distance matrix using \texttt{snp-dists}:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{snp{-}dists}\NormalTok{ gubbins.masked.aln }\KeywordTok{|} \FunctionTok{sed} \StringTok{\textquotesingle{}s/\textbackslash{}t/,/g\textquotesingle{}} \OperatorTok{\textgreater{}}\NormalTok{ raw\_outbreak\_matrix.csv}
\end{Highlighting}
\end{Shaded}

Now download the \texttt{raw\_outbreak\_matrix.csv}, navigate to \href{https://graphsnp.fordelab.com/}{GraphSNP} in your browser, and upload the \texttt{raw\_outbreak\_matrix.csv} as your Alignment/matrix.

\pandocbounded{\includegraphics[keepaspectratio]{content-files/graphsnp_upload.jpg}}

Then click on ``Graph'' at the top of the page (may be hidden behind 3 horizontal lines on smaller screens), increase your ``Cutoff number'' to 50, and then hit the ``Create Graph'' button.

\pandocbounded{\includegraphics[keepaspectratio]{content-files/graphsnp_cluster.jpg}}

This will create a minimum spanning tree grouped using a 50 SNP cut-off.

\textbf{Which genomes do you think you can eliminate from being part of these immediate outbreak cluster?}

Based on the graph, isolates P29 \& P34-P38 can be eliminated. These were the ST22 isolates identified by \texttt{mlst} that poppunk convinced us to look at a bit more closely. We can see the closest is only \textasciitilde80 SNPs from our outbreak cluster.

Let's also look at these isolates using a traditional phylogenetic approach. Go back to the server and run the following command to build a maximum-likelihood tree using \texttt{iqtree}:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{iqtree} \AttributeTok{{-}s}\NormalTok{ gubbins.masked.aln}
\end{Highlighting}
\end{Shaded}

This will generate a lot of outputs but if you download the newick formatted phylogeny \texttt{gubbins.masked.aln.treefile} and go to \href{https://microreact.org/upload}{microreact} we can visualise the tree.

Hit the ``Upload'' button and select your treefile.
\pandocbounded{\includegraphics[keepaspectratio]{content-files/microreact_upload.jpg}}

\pandocbounded{\includegraphics[keepaspectratio]{content-files/microreact_upload2.jpg}}

Then hit the settings slider icon at the top right

\pandocbounded{\includegraphics[keepaspectratio]{content-files/microreact_upload3.jpg}}

Finally, select radial/unrooted tree.

\pandocbounded{\includegraphics[keepaspectratio]{content-files/microreact_upload4.jpg}}

\textbf{Does the phylogeny show the same genomes as being outside the main outbreak cluster}

Yes, P37 \& P38 are close to the main outbreak cluster and could be included but for now we will exclude them.

Now we have refined our final set of suspected outbreak isolates we can create our final alignment of just these sequences.

\textbf{Create a SNP distance matrix and phylogeny for just the final outbreak isolates by repeating the above steps with a modified ska\_input (if you create a new folder you'll avoid getting mixed up with your new datas).}

A pre-computed distance matrix and phylogeny can be copied from \texttt{\textasciitilde{}/CourseData/module4/refined\_outbreak\_matrix.csv} and \texttt{\textasciitilde{}/CourseData/module4/refined.gubbins.masked.aln.treefile}

\#\#\# Transmission Inference

With our refined outbreak distance matrix and phylogeny we are going to perform some transmission analyses by combining these with some of our context data.

First we are going to use the \href{https://pmc.ncbi.nlm.nih.gov/articles/PMC3183872/}{SeqTrack} method as implemented in \href{https://graphsnp.fordelab.com/}{GraphSNP}.

To do this download \texttt{contextual\_metadata.csv} and your refined distance matrix (e.g., \texttt{refined\_outbreak\_matrix.csv} or whatever you have named it) and then navigate to \href{https://graphsnp.fordelab.com/}{GraphSNP}.\\
This time you must upload the new distance matrix under Alignment/matrix and the metadata table under Metadata.

\pandocbounded{\includegraphics[keepaspectratio]{content-files/graphsnp_upload.jpg}}

Then navigate to ``Graph'' but this time select analysis type ``transmission'' and click ``Create Graph''

\pandocbounded{\includegraphics[keepaspectratio]{content-files/graphsnp_transmission.jpg}}

\textbf{Which person is inferred to have infected the largest number of other patients?}

P8 or P4

\textbf{Which baby/babies was/were inferred to be infected by a parent?}

P13 and P15

Congratulations you've performed your first transmission analysis!

The next step would be to try and perform a more sophisticated transmission inference method using \texttt{TransPhylo}.
However, this would require us to infer a time-scaled phylogeny and you'll discover more about how to do that in the next module!

\chapter{Module 5 Phylodynamics}\label{module-5-phylodynamics}

\section{Lecture}\label{lecture-4}

\section{Lab}\label{lab-4}

\bibliography{book.bib,packages.bib}

\end{document}
